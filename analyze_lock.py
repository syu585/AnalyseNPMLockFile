#!/usr/bin/env python3
"""
Script to analyze lock files from various package managers:
- Supports: bun.lock, package-lock.json (npm), yarn.lock, pnpm-lock.yaml, deno.lock
- Can analyze a single lock file or recursively find and analyze all lock files in a directory
- Extract all packages with their versions
- Query release time for each version using npm registry API
- Find packages released after a specific date
"""

import json
import re
import requests
import sys
import yaml
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from urllib.parse import quote


def find_lock_files(directory: str) -> List[Tuple[str, str]]:
    """
    Recursively find all lock files in a directory.
    
    Args:
        directory: Path to the directory to search
        
    Returns:
        List of (file_path, format_type) tuples
    """
    lock_file_patterns = {
        'bun.lock': 'bun',
        'bun.lockb': 'bun',
        'package-lock.json': 'npm',
        'yarn.lock': 'yarn',
        'pnpm-lock.yaml': 'pnpm',
        'deno.lock': 'deno',
    }
    
    found_files = []
    directory_path = Path(directory)
    
    if not directory_path.exists():
        print(f"Error: Directory '{directory}' does not exist", file=sys.stderr)
        return []
    
    if not directory_path.is_dir():
        print(f"Error: '{directory}' is not a directory", file=sys.stderr)
        return []
    
    # Recursively search for lock files
    for pattern, format_type in lock_file_patterns.items():
        for file_path in directory_path.rglob(pattern):
            found_files.append((str(file_path), format_type))
    
    return found_files


def detect_lock_file_format(lock_file_path: str) -> str:
    """
    Auto-detect the lock file format based on filename and content.
    
    Args:
        lock_file_path: Path to the lock file
        
    Returns:
        Format name: 'bun', 'npm', 'yarn', 'pnpm', or 'deno'
    """
    path = Path(lock_file_path)
    filename = path.name.lower()
    
    # Check by filename
    if filename == 'bun.lock' or filename == 'bun.lockb':
        return 'bun'
    elif filename == 'package-lock.json':
        return 'npm'
    elif filename == 'yarn.lock':
        return 'yarn'
    elif filename == 'pnpm-lock.yaml':
        return 'pnpm'
    elif filename == 'deno.lock':
        return 'deno'
    
    # Try to detect by content
    try:
        with open(lock_file_path, 'r') as f:
            first_line = f.readline().strip()
            if first_line.startswith('# THIS IS AN AUTOGENERATED FILE'):
                return 'yarn'
            
            # Try parsing as JSON
            f.seek(0)
            content = f.read()
            data = json.loads(content)
            
            if 'lockfileVersion' in data:
                return 'npm'
            elif 'version' in data and 'packages' in data and isinstance(list(data.get('packages', {}).values())[0] if data.get('packages') else None, list):
                return 'bun'
            elif 'remote' in data or 'npm' in data:
                return 'deno'
    except:
        pass
    
    # Default fallback
    print(f"Warning: Could not auto-detect format for {lock_file_path}, defaulting to 'npm'", file=sys.stderr)
    return 'npm'


def parse_bun_lock(lock_file_path: str) -> List[Tuple[str, str]]:
    """
    Parse bun.lock file and extract package names with their versions.
    Handles JavaScript-like JSON with trailing commas.
    
    Args:
        lock_file_path: Path to the bun.lock file
        
    Returns:
        List of (package_name, version) tuples
    """
    with open(lock_file_path, 'r') as f:
        content = f.read()
        
    # Remove trailing commas before closing braces/brackets (JavaScript-style JSON)
    # This regex handles trailing commas in objects and arrays
    content = re.sub(r',(\s*[}\]])', r'\1', content)
    
    try:
        lock_data = json.loads(content)
    except json.JSONDecodeError as e:
        print(f"Error parsing bun.lock file: {e}", file=sys.stderr)
        print("The file may have syntax that's not compatible with JSON.", file=sys.stderr)
        sys.exit(1)
    
    packages = []
    
    # Parse the packages section
    if 'packages' in lock_data:
        for package_key, package_info in lock_data['packages'].items():
            if isinstance(package_info, list) and len(package_info) > 0:
                # Format: ["package@version", ...]
                package_full_name = package_info[0]
                
                # Extract package name and version
                if '@' in package_full_name:
                    # Handle scoped packages (e.g., @babel/core@7.27.4)
                    if package_full_name.startswith('@'):
                        parts = package_full_name.rsplit('@', 1)
                        if len(parts) == 2:
                            package_name = parts[0]
                            version = parts[1]
                            packages.append((package_name, version))
                    else:
                        parts = package_full_name.split('@')
                        if len(parts) >= 2:
                            package_name = parts[0]
                            version = parts[1]
                            packages.append((package_name, version))
    
    return packages


def parse_npm_lock(lock_file_path: str) -> List[Tuple[str, str]]:
    """
    Parse package-lock.json (npm) file and extract package names with their versions.
    
    Args:
        lock_file_path: Path to the package-lock.json file
        
    Returns:
        List of (package_name, version) tuples
    """
    with open(lock_file_path, 'r') as f:
        lock_data = json.load(f)
    
    packages = []
    
    # npm v7+ uses 'packages' field
    if 'packages' in lock_data:
        for package_path, package_info in lock_data['packages'].items():
            if package_path and package_path != '' and 'version' in package_info:
                # Extract package name from path (e.g., "node_modules/@babel/core" -> "@babel/core")
                package_name = package_path.replace('node_modules/', '')
                version = package_info['version']
                if package_name:
                    packages.append((package_name, version))
    
    # npm v5-6 uses 'dependencies' field
    elif 'dependencies' in lock_data:
        def extract_dependencies(deps_dict, packages_list):
            for package_name, package_info in deps_dict.items():
                if isinstance(package_info, dict) and 'version' in package_info:
                    packages_list.append((package_name, package_info['version']))
                # Recursively handle nested dependencies
                if isinstance(package_info, dict) and 'dependencies' in package_info:
                    extract_dependencies(package_info['dependencies'], packages_list)
        
        extract_dependencies(lock_data['dependencies'], packages)
    
    return packages


def parse_yarn_lock(lock_file_path: str) -> List[Tuple[str, str]]:
    """
    Parse yarn.lock file and extract package names with their versions.
    
    Args:
        lock_file_path: Path to the yarn.lock file
        
    Returns:
        List of (package_name, version) tuples
    """
    packages = []
    
    with open(lock_file_path, 'r') as f:
        content = f.read()
    
    # Yarn lock format uses patterns like:
    # package-name@^1.0.0:
    #   version "1.0.0"
    # or for scoped packages:
    # "@scope/package@^1.0.0":
    #   version "1.0.0"
    
    lines = content.split('\n')
    current_package = None
    
    for i, line in enumerate(lines):
        # Check for package name
        # Match both regular and scoped packages
        # Pattern: "package@version:" or package@version: or "@scope/package@version:"
        pkg_match = re.match(r'^"?(@?[^"\s][^"]*?)@[^:]+:\s*$', line)
        if pkg_match:
            current_package = pkg_match.group(1)
            # Remove quotes if present
            current_package = current_package.strip('"')
        
        # Check for version in the next few lines
        elif current_package and line.strip().startswith('version '):
            version_match = re.match(r'^\s+version\s+"([^"]+)"', line)
            if version_match:
                version = version_match.group(1)
                packages.append((current_package, version))
                current_package = None
    
    return packages


def parse_pnpm_lock(lock_file_path: str) -> List[Tuple[str, str]]:
    """
    Parse pnpm-lock.yaml file and extract package names with their versions.
    
    Args:
        lock_file_path: Path to the pnpm-lock.yaml file
        
    Returns:
        List of (package_name, version) tuples
    """
    try:
        with open(lock_file_path, 'r') as f:
            lock_data = yaml.safe_load(f)
    except Exception as e:
        print(f"Error parsing pnpm-lock.yaml file: {e}", file=sys.stderr)
        print("Make sure PyYAML is installed: pip install pyyaml", file=sys.stderr)
        sys.exit(1)
    
    packages = []
    
    # pnpm uses 'packages' field with format: /package-name/version:
    if 'packages' in lock_data:
        for package_key, package_info in lock_data['packages'].items():
            # Format: '/package-name/1.0.0' or '/@scope/package-name/1.0.0'
            if package_key.startswith('/'):
                parts = package_key[1:].rsplit('/', 1)
                if len(parts) == 2:
                    package_name = parts[0]
                    version = parts[1]
                    # Clean version (remove any trailing metadata like _1, etc.)
                    version = re.sub(r'_\d+$', '', version)
                    packages.append((package_name, version))
    
    return packages


def parse_deno_lock(lock_file_path: str) -> List[Tuple[str, str]]:
    """
    Parse deno.lock file and extract npm package names with their versions.
    
    Args:
        lock_file_path: Path to the deno.lock file
        
    Returns:
        List of (package_name, version) tuples
    """
    with open(lock_file_path, 'r') as f:
        lock_data = json.load(f)
    
    packages = []
    
    # Deno uses 'npm' field for npm packages
    if 'npm' in lock_data and 'specifiers' in lock_data['npm']:
        for package_spec, version_spec in lock_data['npm']['specifiers'].items():
            # Format: "package-name@1.0.0": "1.0.0" or "@scope/package@1.0.0": "1.0.0"
            if '@' in package_spec:
                # Handle scoped packages
                if package_spec.startswith('@'):
                    parts = package_spec.rsplit('@', 1)
                    if len(parts) == 2:
                        package_name = parts[0]
                        # Use the resolved version from value if available
                        version = version_spec.split('@')[-1] if '@' in version_spec else version_spec
                        packages.append((package_name, version))
                else:
                    parts = package_spec.split('@')
                    if len(parts) >= 2:
                        package_name = parts[0]
                        version = version_spec.split('@')[-1] if '@' in version_spec else version_spec
                        packages.append((package_name, version))
    
    return packages


def parse_lock_file(lock_file_path: str, format_type: Optional[str] = None) -> List[Tuple[str, str]]:
    """
    Parse lock file and extract package names with their versions.
    Auto-detects format if not specified.
    
    Args:
        lock_file_path: Path to the lock file
        format_type: Lock file format ('bun', 'npm', 'yarn', 'pnpm', 'deno') or None for auto-detect
        
    Returns:
        List of (package_name, version) tuples
    """
    # Auto-detect if format not specified
    if format_type is None:
        format_type = detect_lock_file_format(lock_file_path)
    
    format_type = format_type.lower()
    
    # Call appropriate parser
    parsers = {
        'bun': parse_bun_lock,
        'npm': parse_npm_lock,
        'yarn': parse_yarn_lock,
        'pnpm': parse_pnpm_lock,
        'deno': parse_deno_lock,
    }
    
    if format_type not in parsers:
        print(f"Error: Unsupported format '{format_type}'", file=sys.stderr)
        print(f"Supported formats: {', '.join(parsers.keys())}", file=sys.stderr)
        sys.exit(1)
    
    return parsers[format_type](lock_file_path)


def get_package_release_date(package_name: str, version: str, verbose: bool = False) -> Dict:
    """
    Query npm registry API to get the release date for a specific package version.
    
    Args:
        package_name: Name of the npm package
        version: Version of the package
        verbose: Whether to print progress messages
        
    Returns:
        Dictionary with package info including release date
    """
    try:
        # Encode package name for URL (important for scoped packages)
        encoded_name = quote(package_name, safe='@/')
        url = f"https://registry.npmjs.org/{encoded_name}"
        
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        
        # Get the time information for the specific version
        if 'time' in data and version in data['time']:
            release_date = data['time'][version]
        else:
            release_date = "Unknown"
        
        if verbose:
            print(f"✓ {package_name}@{version}", file=sys.stderr)
            
        return {
            'package': package_name,
            'version': version,
            'release_date': release_date
        }
            
    except requests.exceptions.RequestException as e:
        if verbose:
            print(f"✗ {package_name}@{version}: {e}", file=sys.stderr)
        return {
            'package': package_name,
            'version': version,
            'release_date': "Error"
        }
    except Exception as e:
        if verbose:
            print(f"✗ {package_name}@{version}: {e}", file=sys.stderr)
        return {
            'package': package_name,
            'version': version,
            'release_date': "Error"
        }


def fetch_release_dates_concurrent(packages: List[Tuple[str, str]], max_workers: int = 10, verbose: bool = False) -> List[Dict]:
    """
    Fetch release dates for multiple packages concurrently.
    
    Args:
        packages: List of (package_name, version) tuples
        max_workers: Maximum number of concurrent workers (default: 10)
        verbose: Whether to print progress messages
        
    Returns:
        List of package dictionaries with release dates
    """
    packages_with_dates = []
    
    if verbose:
        print(f"Fetching release dates for {len(packages)} packages using {max_workers} concurrent workers...", file=sys.stderr)
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        future_to_package = {
            executor.submit(get_package_release_date, pkg_name, version, verbose): (pkg_name, version)
            for pkg_name, version in packages
        }
        
        # Collect results as they complete
        completed = 0
        for future in as_completed(future_to_package):
            completed += 1
            try:
                result = future.result()
                packages_with_dates.append(result)
                
                if verbose and completed % 10 == 0:
                    print(f"Progress: {completed}/{len(packages)} packages fetched", file=sys.stderr)
            except Exception as e:
                pkg_name, version = future_to_package[future]
                print(f"Error processing {pkg_name}@{version}: {e}", file=sys.stderr)
                packages_with_dates.append({
                    'package': pkg_name,
                    'version': version,
                    'release_date': "Error"
                })
    
    if verbose:
        print(f"Completed fetching all {len(packages)} packages", file=sys.stderr)
    
    return packages_with_dates


def filter_packages_after_date(packages_with_dates: List[Dict], cutoff_date: str) -> List[Dict]:
    """
    Filter packages released after a specific date.
    
    Args:
        packages_with_dates: List of package dictionaries with release dates
        cutoff_date: ISO 8601 date string (e.g., "2024-01-01")
        
    Returns:
        List of packages released after the cutoff date
    """
    from datetime import timezone
    
    try:
        # Parse cutoff date and make it timezone-aware (UTC)
        cutoff = datetime.fromisoformat(cutoff_date.replace('Z', '+00:00'))
        # If the parsed datetime is naive (no timezone), make it UTC
        if cutoff.tzinfo is None:
            cutoff = cutoff.replace(tzinfo=timezone.utc)
    except ValueError:
        print(f"Invalid date format: {cutoff_date}. Use ISO 8601 format (e.g., '2024-01-01')", file=sys.stderr)
        return []
    
    filtered = []
    for pkg in packages_with_dates:
        if pkg['release_date'] not in ['Unknown', 'Error']:
            try:
                release = datetime.fromisoformat(pkg['release_date'].replace('Z', '+00:00'))
                # Ensure release date is timezone-aware
                if release.tzinfo is None:
                    release = release.replace(tzinfo=timezone.utc)
                    
                if release > cutoff:
                    filtered.append(pkg)
            except ValueError:
                continue
    
    return filtered


def main():
    """Main function to run the analysis."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Analyze lock files from various package managers and find packages released after a specific date'
    )
    parser.add_argument(
        'path',
        help='Path to lock file or directory containing lock files. If directory, will recursively search for all supported lock files.'
    )
    parser.add_argument(
        '--format',
        choices=['bun', 'npm', 'yarn', 'pnpm', 'deno', 'auto'],
        default='auto',
        help='Lock file format (default: auto-detect). Only applicable when path is a single file.'
    )
    parser.add_argument(
        '--date',
        required=True,
        help='Cutoff date in ISO 8601 format (e.g., 2024-01-01). Packages released after this date will be listed.'
    )
    parser.add_argument(
        '--output',
        help='Optional output file path (JSON format). If not specified, prints to stdout.'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Show progress messages'
    )
    parser.add_argument(
        '--workers',
        type=int,
        default=10,
        help='Number of concurrent workers for fetching package data (default: 10)'
    )
    
    args = parser.parse_args()
    
    path = Path(args.path)
    
    # Check if path is a file or directory
    if path.is_file():
        # Single file mode
        lock_files = [(str(path), None if args.format == 'auto' else args.format)]
        if args.verbose:
            print(f"Processing single lock file: {args.path}", file=sys.stderr)
    elif path.is_dir():
        # Directory mode - find all lock files recursively
        if args.verbose:
            print(f"Searching for lock files in directory: {args.path}", file=sys.stderr)
        
        lock_files = find_lock_files(args.path)
        
        if not lock_files:
            print(f"No lock files found in directory: {args.path}", file=sys.stderr)
            sys.exit(1)
        
        if args.verbose:
            print(f"Found {len(lock_files)} lock file(s):", file=sys.stderr)
            for file_path, format_type in lock_files:
                print(f"  - {file_path} ({format_type})", file=sys.stderr)
    else:
        print(f"Error: Path '{args.path}' does not exist or is not accessible", file=sys.stderr)
        sys.exit(1)
    
    # Process all lock files
    all_packages = []
    all_packages_set = set()  # To avoid duplicates across files
    lock_files_processed = []
    
    for lock_file_path, format_type in lock_files:
        if args.verbose:
            print(f"\nParsing {lock_file_path}...", file=sys.stderr)
        
        try:
            packages = parse_lock_file(lock_file_path, format_type)
            
            if args.verbose:
                detected_format = format_type or detect_lock_file_format(lock_file_path)
                print(f"  Format: {detected_format}", file=sys.stderr)
                print(f"  Found {len(packages)} packages", file=sys.stderr)
            
            # Add unique packages to the collection
            new_packages = 0
            for pkg in packages:
                pkg_key = (pkg[0], pkg[1])  # (name, version) tuple
                if pkg_key not in all_packages_set:
                    all_packages.append(pkg)
                    all_packages_set.add(pkg_key)
                    new_packages += 1
            
            if args.verbose and len(lock_files) > 1:
                print(f"  Added {new_packages} unique packages", file=sys.stderr)
            
            lock_files_processed.append({
                'path': lock_file_path,
                'format': format_type or detect_lock_file_format(lock_file_path),
                'packages_count': len(packages)
            })
            
        except Exception as e:
            print(f"Error processing {lock_file_path}: {e}", file=sys.stderr)
            continue
    
    if not all_packages:
        print("No packages found in any lock files", file=sys.stderr)
        sys.exit(1)
    
    if args.verbose:
        print(f"\nTotal unique packages across all files: {len(all_packages)}", file=sys.stderr)
    
    # Get release dates for all packages concurrently
    packages_with_dates = fetch_release_dates_concurrent(
        all_packages, 
        max_workers=args.workers, 
        verbose=args.verbose
    )
    
    # Filter packages by date
    if args.verbose:
        print(f"\nFiltering packages released after {args.date}...", file=sys.stderr)
    
    filtered_packages = filter_packages_after_date(packages_with_dates, args.date)
    
    # Sort by release date (newest first)
    filtered_packages.sort(key=lambda x: x['release_date'], reverse=True)
    
    # Prepare output
    output_data = {
        'cutoff_date': args.date,
        'lock_files_processed': lock_files_processed,
        'total_packages': len(all_packages),
        'packages_after_date': len(filtered_packages),
        'packages': filtered_packages
    }
    
    # Write output
    if args.output:
        with open(args.output, 'w') as f:
            json.dump(output_data, f, indent=2)
        if args.verbose:
            print(f"\nResults written to {args.output}", file=sys.stderr)
    else:
        print(json.dumps(output_data, indent=2))
    
    # Print summary
    if args.verbose:
        print(f"\nSummary:", file=sys.stderr)
        print(f"Lock files processed: {len(lock_files_processed)}", file=sys.stderr)
        print(f"Total unique packages: {len(all_packages)}", file=sys.stderr)
        print(f"Packages released after {args.date}: {len(filtered_packages)}", file=sys.stderr)


if __name__ == '__main__':
    main()

